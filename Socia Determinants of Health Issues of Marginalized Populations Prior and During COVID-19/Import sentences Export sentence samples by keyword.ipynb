{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "import os\n",
    "import spacy\n",
    "import urllib.parse as url\n",
    "import re, string, unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['asians','blacks']\n",
    "train_eval = ['evaluation','training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_words = {'Asian American':'Asian_American','high school':'high_school','High school':'High_school',\n",
    "                'White American':'White_American','Black american':'Black_American',\n",
    "                'White pe':'White_pe','Black pe':'Black_pe','Black wom':'Black_wom',\n",
    "                'White wom':'White_wom','Black man':'Black_man','white man':'White_man','CaucAsian':'Caucasian',\n",
    "                'Black men':'Black_men','White men':'White_men','African American':'African_American',\n",
    "                'Asian pe':'Asian_pe','native American':'Native_American','Latin American':'Latin_American',\n",
    "                'violent crime':'violent_crime','Violent crime':'Violent_crime','police brutality':'police_brutality',\n",
    "                'Police brutality':'Police_brutality','black lives matter':'Black_Lives_Matter',\n",
    "                'American Indian':'American_Indian','puerto rican':'Puerto_Rican','Puerto rican':'Puerto_Rican',\n",
    "                'African-Amer':'African_Amer','asian-Amer':'Asian_Amer','Asian-Amer':'Asian_Amer','asian pe':'Asian_pe',\n",
    "                'asian man':'Asian_man','asian men':'Asian_men','asian wom':'Asian_wom','white wom':'White_wom',\n",
    "                'Asian man':'Asian_man','Asian men':'Asian_men','Asian wom':'Asian_wom','white men':'White_men',\n",
    "                'poc ':'POC ','hite supremac':'hite_supremac','brazil':'Brazil','caucAsian':'Caucasian','Asian pe':'Asian_pe',\n",
    "                'Black lives matter':'Black_Lives_Matter','Native American':'Native_American','CaucAsian':'Caucasian',\n",
    "                'black men':'Black_men','black wom':'Black_wom','White American':'White_American','black man':'Black_man',\n",
    "                'Black American':'Black_American',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_words = ['poverty', 'employment', 'homeless', 'job', 'business', 'wealth', 'welfare','educat', \n",
    "             'high school', 'college', 'universit', 'school','protest', 'discriminat', 'arrest', \n",
    "             'immigra', 'racis', 'segregat', 'communit', 'police brutality', 'blm','stereotyp', \n",
    "             'black lives matter', 'violent crime', 'neighborhood', 'police', 'cops','crime', \n",
    "             'White man','White men','Whites','Hispanic', 'Latin', 'Latin American', 'Chinese', \n",
    "             'Indian', 'Native American', 'Filipino', 'Korean', 'Japanese', 'Vietnamese', \n",
    "             'Mexican', 'Puerto Rican', 'Arab', 'Caucasian','Brazilian', ' poc ','Black pe',\n",
    "             'white supremac', 'African Amer','Asian Amer','White pe','Asian pe','White wom',\n",
    "             'Black wom','Asian wom','Asian man','Black man','Asian men','Black men','black american',\n",
    "             'white american', ]\n",
    "             #'Blacks','Asians',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_words_dict = {'poverty':'ECON', 'employment':'ECON', 'homeless':'ECON', 'job':'ECON','welfare':'ECON',\n",
    "                  'business':'ECON', 'wealth':'ECON', 'educat':'EDU','high_school':'EDU','school':'EDU',  \n",
    "                  'college':'EDU', 'universit':'EDU', 'protest':'SCC', 'discriminat':'SCC','stereotyp':'SCC', \n",
    "                  'arrest':'SCC','immigra':'SCC', 'racis':'SCC', 'segregat':'SCC', 'communit':'SCC',\n",
    "                  'police_brutality':'SCC', 'blm':'SCC','black_lives_matter':'SCC','white_supremac':'SCC', \n",
    "                  'police':'SCC','cop':'SCC','cops':'SCC','violent_crime':'NBE', 'neighborhood':'NBE','crime':'NBE', \n",
    "                  'Asians':'RETH', 'Whites':'RETH', 'Blacks':'RETH', 'Hispanic':'RETH', 'Latin':'RETH',\n",
    "                  'Latin American':'RETH', 'Chinese':'RETH','Indian':'RETH', 'Native_American':'RETH',\n",
    "                  'Filipino':'RETH', 'Korean':'RETH', 'Japanese':'RETH', 'Vietnamese':'RETH', \n",
    "                  'Mexican':'RETH', 'Puerto_Rican':'RETH', 'Arab':'RETH', 'Caucasian':'RETH', \n",
    "                  'n_Amer':'RETH', 'American_Indian':'RETH','Asian_wom':'RETH','Black_American':'RETH',\n",
    "                  'Black_wom':'RETH','Asian_man':'RETH','Black_man':'RETH','Asian_men':'RETH',\n",
    "                  'Black_men':'RETH','White_wom':'RETH','Asian_pe':'RETH','Black_pe':'RETH','Brazilian':'RETH',\n",
    "                  'White_man':'RETH','White_men':'RETH', 'White_pe':'RETH','blm':'SCC','White_American':'RETH',\n",
    "                  'POC':'RETH', }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_underscore(text):\n",
    "    \"\"\"Replace underscore with space if str len is > 4, up to 2 are replaced\"\"\"\n",
    "    if len(str(text)) > 4 and \"_\" in text:\n",
    "        return text.replace(\"_\", \" \", 2)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports sentences from text file and load into a DataFrame\n",
    "## Changes words with space and replace with underscore - save modified text to seperate text files.\n",
    "def extract_sents(kw):\n",
    "    lines = []\n",
    "    for kl in keyword_list:\n",
    "        with open(os.getcwd() + r'/data/sentence_samples/%s.txt'%kl) as file_in:\n",
    "            for line in file_in:\n",
    "                if kw.casefold() in str(line).casefold():\n",
    "                    lines.append(line)\n",
    "    print ('The total number of lines in %s is %s'%(kw,len(lines)))\n",
    "    df = pd.DataFrame(lines,columns=['sents'])\n",
    "    df.style.set_properties(subset=[\"sents\"], **{'text-align': 'left'})\n",
    "    df.sents = df.sents.apply(str).astype('U').values\n",
    "    for old, new in replace_words.items():\n",
    "        df.sents = df.sents.str.replace(old, new, regex=False)# continue working on ignorecase\n",
    "    with open(os.getcwd() + r'/data/sentence_samples/keywords/%s.txt'%kw, 'w') as f:\n",
    "        np.savetxt(f,df.sents, fmt='%s', newline='')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports n sentences from text file and load into a DataFrame\n",
    "##  save 70% sentences as training data, 30% evaluation to respective files/folders.\n",
    "def extract_sents_partial(kw):\n",
    "    lines = []\n",
    "    with open(os.getcwd() + r'/data/sentence_samples/keywords/%s.txt'%kw) as file_in:\n",
    "        for line in file_in:\n",
    "            lines.append(line)\n",
    "    if len(lines) < 1000:\n",
    "        df = pd.DataFrame(lines,columns=['sents'])\n",
    "    else:\n",
    "        df = pd.DataFrame(lines[:1000],columns=['sents'])\n",
    "    print ('The total number of lines in %s is %s'%(kw,df.shape[0]))\n",
    "    df.style.set_properties(subset=[\"sents\"], **{'text-align': 'left'})\n",
    "    df.sents = df.sents.apply(str).astype('U').values\n",
    "\n",
    "    begin = int((df.shape[0] * 0.7))\n",
    "    with open(os.getcwd() + r'/data/sentence_samples/keywords/training/%s.txt'%kw, 'w') as f:\n",
    "        np.savetxt(f,df.sents.iloc[:begin], fmt='%s', newline='') \n",
    "    with open(os.getcwd() + r'/data/sentence_samples/keywords/evaluation/%s.txt'%kw, 'w') as f:\n",
    "        np.savetxt(f,df.sents.iloc[begin:], fmt='%s', newline='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_files(te):\n",
    "    lines = []\n",
    "    for kl in ner_words:\n",
    "        with open(os.getcwd() + r'/data/sentence_samples/keywords/%s/%s.txt'%(te,kl)) as file_in:\n",
    "            for line in file_in:\n",
    "                lines.append(line)\n",
    "    #print ('The total number of lines in %s is %s'%(kw,len(lines)))\n",
    "    df = pd.DataFrame(lines,columns=['sents'])\n",
    "    df.style.set_properties(subset=[\"sents\"], **{'text-align': 'left'})\n",
    "    df.sents = df.sents.apply(str).astype('U').values\n",
    "    with open(os.getcwd() + r'/data/sentence_samples/keywords/%s/%s.txt'%(te,te), 'a') as f:\n",
    "        np.savetxt(f,df.sents, fmt='%s', newline='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words (keyword): \n",
    "    words = []\n",
    "    with open(os.getcwd() + r'/data/sentence_samples/keywords/%s.txt'%keyword) as file_in:\n",
    "        for line in file_in:\n",
    "            doc = nlp(str(line))\n",
    "            for token in doc:\n",
    "                if not token.text.isspace():\n",
    "                    words.append([token.text])\n",
    "    words = pd.DataFrame(words,columns=['Words'])\n",
    "    words['Tags'] = 'O'\n",
    "    for old, new in ner_words_dict.items():\n",
    "        words.Tags = np.where(words.Words.str.contains(old, case=False), new, words.Tags)\n",
    "    words.Words = words.Words.apply(remove_underscore).astype('U').values\n",
    "    words.to_csv(os.getcwd() + r'/data/sentence_samples/keywords/tsv/%s.tsv'%keyword, sep=\"\\t\", index=False,  encoding=\"utf-8\")\n",
    "    # put 'header = False,' if you want to save with no headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_combined (keyword): \n",
    "    words = []\n",
    "    with open(os.getcwd() + r'/data/sentence_samples/keywords/%s/%s_1.txt'%(keyword,keyword)) as file_in:\n",
    "        for line in file_in:\n",
    "            doc = nlp(str(line))\n",
    "            for token in doc:\n",
    "                if not token.text.isspace():\n",
    "                    words.append([token.text])\n",
    "    words = pd.DataFrame(words,columns=['Words'])\n",
    "    words['Tags'] = 'O'\n",
    "    for old, new in ner_words_dict.items():\n",
    "        words.Tags = np.where(words.Words.str.contains(old, case=False), new, words.Tags)\n",
    "    words.Words = words.Words.apply(remove_underscore).astype('U').values\n",
    "    words.to_csv(os.getcwd() + r'/data/sentence_samples/keywords/%s/tsv/%s_1.tsv'%(keyword,keyword), sep=\"\\t\", index=False,  encoding=\"utf-8\")\n",
    "    # put 'header = False,' if you want to save with no headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of lines in poverty is 2435\n",
      "The total number of lines in employment is 1550\n",
      "The total number of lines in homeless is 271\n",
      "The total number of lines in job is 3598\n",
      "The total number of lines in business is 2036\n",
      "The total number of lines in wealth is 2598\n",
      "The total number of lines in welfare is 1980\n",
      "The total number of lines in educat is 4439\n",
      "The total number of lines in high school is 738\n",
      "The total number of lines in college is 3322\n",
      "The total number of lines in universit is 1533\n",
      "The total number of lines in school is 6143\n",
      "The total number of lines in protest is 1359\n",
      "The total number of lines in discriminat is 7659\n",
      "The total number of lines in arrest is 1948\n",
      "The total number of lines in immigra is 5373\n",
      "The total number of lines in racis is 38798\n",
      "The total number of lines in segregat is 2322\n",
      "The total number of lines in communit is 4437\n",
      "The total number of lines in police brutality is 570\n",
      "The total number of lines in blm is 683\n",
      "The total number of lines in stereotyp is 5133\n",
      "The total number of lines in black lives matter is 257\n",
      "The total number of lines in violent crime is 1756\n",
      "The total number of lines in neighborhood is 1813\n",
      "The total number of lines in police is 6120\n",
      "The total number of lines in cops is 2963\n",
      "The total number of lines in crime is 12504\n",
      "The total number of lines in White man is 1041\n",
      "The total number of lines in White men is 1564\n",
      "The total number of lines in Whites is 55762\n",
      "The total number of lines in Hispanic is 15898\n",
      "The total number of lines in Latin is 9745\n",
      "The total number of lines in Latin American is 274\n",
      "The total number of lines in Chinese is 5616\n",
      "The total number of lines in Indian is 7764\n",
      "The total number of lines in Native American is 2453\n",
      "The total number of lines in Filipino is 793\n",
      "The total number of lines in Korean is 2393\n",
      "The total number of lines in Japanese is 2900\n",
      "The total number of lines in Vietnamese is 531\n",
      "The total number of lines in Mexican is 6120\n",
      "The total number of lines in Puerto Rican is 191\n",
      "The total number of lines in Arab is 4288\n",
      "The total number of lines in Caucasian is 2083\n",
      "The total number of lines in Brazilian is 153\n",
      "The total number of lines in  poc  is 608\n",
      "The total number of lines in Black pe is 10572\n",
      "The total number of lines in white supremac is 2040\n",
      "The total number of lines in African Amer is 1819\n",
      "The total number of lines in Asian Amer is 1471\n",
      "The total number of lines in White pe is 15037\n",
      "The total number of lines in Asian pe is 1109\n",
      "The total number of lines in White wom is 1256\n",
      "The total number of lines in Black wom is 571\n",
      "The total number of lines in Asian wom is 1002\n",
      "The total number of lines in Asian man is 145\n",
      "The total number of lines in Black man is 572\n",
      "The total number of lines in Asian men is 753\n",
      "The total number of lines in Black men is 638\n",
      "The total number of lines in black american is 535\n",
      "The total number of lines in white american is 641\n"
     ]
    }
   ],
   "source": [
    "for kw in ner_words:\n",
    "    extract_sents(kw) #combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of lines in poverty is 1000\n",
      "The total number of lines in employment is 1000\n",
      "The total number of lines in homeless is 271\n",
      "The total number of lines in job is 1000\n",
      "The total number of lines in business is 1000\n",
      "The total number of lines in wealth is 1000\n",
      "The total number of lines in welfare is 1000\n",
      "The total number of lines in educat is 1000\n",
      "The total number of lines in high school is 738\n",
      "The total number of lines in college is 1000\n",
      "The total number of lines in universit is 1000\n",
      "The total number of lines in school is 1000\n",
      "The total number of lines in protest is 1000\n",
      "The total number of lines in discriminat is 1000\n",
      "The total number of lines in arrest is 1000\n",
      "The total number of lines in immigra is 1000\n",
      "The total number of lines in racis is 1000\n",
      "The total number of lines in segregat is 1000\n",
      "The total number of lines in communit is 1000\n",
      "The total number of lines in police brutality is 570\n",
      "The total number of lines in blm is 683\n",
      "The total number of lines in stereotyp is 1000\n",
      "The total number of lines in black lives matter is 257\n",
      "The total number of lines in violent crime is 1000\n",
      "The total number of lines in neighborhood is 1000\n",
      "The total number of lines in police is 1000\n",
      "The total number of lines in cops is 1000\n",
      "The total number of lines in crime is 1000\n",
      "The total number of lines in White man is 1000\n",
      "The total number of lines in White men is 1000\n",
      "The total number of lines in Whites is 1000\n",
      "The total number of lines in Hispanic is 1000\n",
      "The total number of lines in Latin is 1000\n",
      "The total number of lines in Latin American is 274\n",
      "The total number of lines in Chinese is 1000\n",
      "The total number of lines in Indian is 1000\n",
      "The total number of lines in Native American is 1000\n",
      "The total number of lines in Filipino is 793\n",
      "The total number of lines in Korean is 1000\n",
      "The total number of lines in Japanese is 1000\n",
      "The total number of lines in Vietnamese is 531\n",
      "The total number of lines in Mexican is 1000\n",
      "The total number of lines in Puerto Rican is 191\n",
      "The total number of lines in Arab is 1000\n",
      "The total number of lines in Caucasian is 1000\n",
      "The total number of lines in Brazilian is 153\n",
      "The total number of lines in  poc  is 608\n",
      "The total number of lines in Black pe is 1000\n",
      "The total number of lines in white supremac is 1000\n",
      "The total number of lines in African Amer is 1000\n",
      "The total number of lines in Asian Amer is 1000\n",
      "The total number of lines in White pe is 1000\n",
      "The total number of lines in Asian pe is 1000\n",
      "The total number of lines in White wom is 1000\n",
      "The total number of lines in Black wom is 571\n",
      "The total number of lines in Asian wom is 1000\n",
      "The total number of lines in Asian man is 145\n",
      "The total number of lines in Black man is 572\n",
      "The total number of lines in Asian men is 753\n",
      "The total number of lines in Black men is 638\n",
      "The total number of lines in black american is 535\n",
      "The total number of lines in white american is 641\n"
     ]
    }
   ],
   "source": [
    "for kw in ner_words:\n",
    "    extract_sents_partial(kw) #combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_eval:\n",
    "    os.remove(os.getcwd() + r'/data/sentence_samples/keywords/%s/%s.txt'%(i,i))\n",
    "    combine_files(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of lines in Puerto Rican is 191\n"
     ]
    }
   ],
   "source": [
    "for kw in ner_words[41:42]:\n",
    "    extract_sents(kw) #Blacks - for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kw in ner_words:\n",
    "    extract_sents(kw) #asians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ner_words[:1]:\n",
    "    get_words(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in train_eval:\n",
    "    get_words_combined(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tags  # of Ent Types\n",
      "0  ECON            2173\n",
      "1   EDU            1753\n",
      "2   NBE            1324\n",
      "3     O          318657\n",
      "4  RETH           25657\n",
      "5   SCC            6085\n",
      "   Tags  # of Ent Types\n",
      "0  ECON            5072\n",
      "1   EDU            4353\n",
      "2   NBE            2791\n",
      "3     O          753571\n",
      "4  RETH           63314\n",
      "5   SCC           14003\n"
     ]
    }
   ],
   "source": [
    "for k in train_eval:\n",
    "    df = pd.read_csv(os.getcwd() + r'/data/sentence_samples/keywords/%s/tsv/%s_1.tsv'%(k,k), sep=\"\\t\", encoding=\"utf-8\")\n",
    "    df1= df.groupby(['Tags'])['Tags'].count().to_frame(name = '# of Ent Types').reset_index()\n",
    "    print(df1)\n",
    "    #total = df1['Entity Label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
